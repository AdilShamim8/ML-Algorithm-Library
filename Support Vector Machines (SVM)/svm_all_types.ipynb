{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4a430b8-cbcc-4bc6-be52-defad57f5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BaseSVM:\n",
    "    \"\"\"\n",
    "    Base class for SVM with batch gradient descent (for Linear and Kernel SVMs).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel=\"linear\", degree=3, gamma=0.1, coef0=1, \n",
    "                 learning_rate=0.001, lambda_param=0.01, iterations=1000):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        kernel : str\n",
    "            Kernel type: \"linear\", \"poly\", \"rbf\", or \"sigmoid\".\n",
    "        degree : int\n",
    "            Degree for polynomial kernel.\n",
    "        gamma : float\n",
    "            Gamma for RBF/poly kernels.\n",
    "        coef0 : float\n",
    "            Independent term in poly/sigmoid kernel.\n",
    "        learning_rate : float\n",
    "            Step size for gradient descent.\n",
    "        lambda_param : float\n",
    "            Regularization parameter (C = 1/lambda_param).\n",
    "        iterations : int\n",
    "            Number of epochs.\n",
    "        \"\"\"\n",
    "        self.kernel = kernel\n",
    "        self.degree = degree\n",
    "        self.gamma = gamma\n",
    "        self.coef0 = coef0\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda_param = lambda_param\n",
    "        self.iterations = iterations\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def _kernel_function(self, X, Y=None):\n",
    "        # Computes the kernel matrix between X and Y\n",
    "        if Y is None:\n",
    "            Y = X\n",
    "        if self.kernel == \"linear\":\n",
    "            return np.dot(X, Y.T)\n",
    "        elif self.kernel == \"poly\":\n",
    "            return (self.gamma * np.dot(X, Y.T) + self.coef0) ** self.degree\n",
    "        elif self.kernel == \"rbf\":\n",
    "            X_norm = np.sum(X ** 2, axis=-1)\n",
    "            Y_norm = np.sum(Y ** 2, axis=-1)\n",
    "            K = -2 * np.dot(X, Y.T) + X_norm[:, None] + Y_norm[None, :]\n",
    "            return np.exp(-self.gamma * K)\n",
    "        elif self.kernel == \"sigmoid\":\n",
    "            return np.tanh(self.gamma * np.dot(X, Y.T) + self.coef0)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown kernel\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the SVM model to training data.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray\n",
    "            Training features (n_samples, n_features).\n",
    "        y : numpy.ndarray\n",
    "            Target values (n_samples,). Must be -1 or 1 for binary.\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        y_ = np.where(y <= 0, -1, 1)\n",
    "        self.X_train = X\n",
    "        self.y_train = y_\n",
    "\n",
    "        if self.kernel == \"linear\":\n",
    "            # Linear SVM via gradient descent (primal)\n",
    "            self.w = np.zeros(n_features)\n",
    "            self.b = 0.0\n",
    "            for _ in range(self.iterations):\n",
    "                for idx, xi in enumerate(X):\n",
    "                    condition = y_[idx] * (np.dot(xi, self.w) + self.b) >= 1\n",
    "                    if condition:\n",
    "                        grad_w = 2 * self.lambda_param * self.w\n",
    "                        grad_b = 0\n",
    "                    else:\n",
    "                        grad_w = 2 * self.lambda_param * self.w - np.dot(xi, y_[idx])\n",
    "                        grad_b = -y_[idx]\n",
    "                    self.w -= self.learning_rate * grad_w\n",
    "                    self.b -= self.learning_rate * grad_b\n",
    "        else:\n",
    "            # Kernel SVM (dual, simplified for demonstration, not optimized)\n",
    "            self.alpha = np.zeros(n_samples)\n",
    "            self.b = 0.0\n",
    "            K = self._kernel_function(X)\n",
    "            for _ in range(self.iterations):\n",
    "                for i in range(n_samples):\n",
    "                    # Calculate decision function for i-th sample\n",
    "                    decision = np.sum(self.alpha * y_ * K[:, i]) + self.b\n",
    "                    condition = y_[i] * decision\n",
    "                    if condition < 1:\n",
    "                        self.alpha[i] += self.learning_rate * (1 - condition)\n",
    "                    # Simple regularization (not a true SMO/dual implementation)\n",
    "            # For prediction, store alpha\n",
    "            self.w = None  # Not used in kernel case\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        if self.kernel == \"linear\":\n",
    "            return np.dot(X, self.w) + self.b\n",
    "        else:\n",
    "            K = self._kernel_function(self.X_train, X)\n",
    "            return np.sum(self.alpha[:, None] * self.y_train[:, None] * K, axis=0) + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.decision_function(X) >= 0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9a092-69eb-4959-90e5-4ed7d73e71a4",
   "metadata": {},
   "source": [
    "> ## Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01d13da4-4316-462b-8773-caaf2512775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate separable data (two classes)\n",
    "np.random.seed(42)\n",
    "X1 = np.random.randn(50, 2) + [2, 2]\n",
    "X2 = np.random.randn(50, 2) + [-2, -2]\n",
    "X = np.vstack([X1, X2])\n",
    "y = np.hstack([np.ones(50), -np.ones(50)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55c6754-dcb1-4072-8cd4-1a5fe1ee0afe",
   "metadata": {},
   "source": [
    "> ### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e8eabc6-61e4-49cb-b84e-8658955e9dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Linear SVM ---\n",
      "Accuracy (Linear): 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Linear SVM ---\")\n",
    "svm_linear = BaseSVM(kernel=\"linear\", learning_rate=0.001, lambda_param=0.01, iterations=1000)\n",
    "svm_linear.fit(X, y)\n",
    "y_pred_linear = svm_linear.predict(X)\n",
    "print(\"Accuracy (Linear):\", np.mean(y_pred_linear == y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43799ee8-8c73-42a8-8d14-88ad06944c76",
   "metadata": {},
   "source": [
    "> ### Polynomial SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d2febc1-15c0-45ef-b479-084c1a40f3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Polynomial SVM ---\n",
      "Accuracy (Poly): 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Polynomial SVM ---\")\n",
    "svm_poly = BaseSVM(kernel=\"poly\", degree=3, gamma=1, coef0=1, learning_rate=0.001, iterations=1000)\n",
    "svm_poly.fit(X, y)\n",
    "y_pred_poly = svm_poly.predict(X)\n",
    "print(\"Accuracy (Poly):\", np.mean(y_pred_poly == y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9fd72-e0f2-4c4f-9b49-8a52eb937dd8",
   "metadata": {},
   "source": [
    "> ### RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ae06913-82b3-4202-b468-5fbd866c207a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RBF SVM ---\n",
      "Accuracy (RBF): 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"--- RBF SVM ---\")\n",
    "svm_rbf = BaseSVM(kernel=\"rbf\", gamma=0.5, learning_rate=0.001, iterations=1000)\n",
    "svm_rbf.fit(X, y)\n",
    "y_pred_rbf = svm_rbf.predict(X)\n",
    "print(\"Accuracy (RBF):\", np.mean(y_pred_rbf == y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa7d4af-d786-4f69-9c50-cd7965dd6a4e",
   "metadata": {},
   "source": [
    "> ### Sigmoid SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a29e457-5a3c-43d1-a367-7efdf0edf183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sigmoid SVM ---\n",
      "Accuracy (Sigmoid): 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Sigmoid SVM ---\")\n",
    "svm_sigmoid = BaseSVM(kernel=\"sigmoid\", gamma=0.01, coef0=0.0, learning_rate=0.001, iterations=1000)\n",
    "svm_sigmoid.fit(X, y)\n",
    "y_pred_sigmoid = svm_sigmoid.predict(X)\n",
    "print(\"Accuracy (Sigmoid):\", np.mean(y_pred_sigmoid == y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
