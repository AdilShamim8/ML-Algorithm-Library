{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e6b311-2810-43ad-b39e-3ce0b4969a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SoftmaxRegressionScratch:\n",
    "    \"\"\"\n",
    "    Multinomial Logistic Regression (Softmax Regression) from scratch using gradient descent.\n",
    "    Supports multi-class classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate=0.1, iterations=1000):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        learning_rate : float\n",
    "            Gradient descent step size.\n",
    "        iterations : int\n",
    "            Number of iterations for gradient descent.\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.weights = None  # Shape: (n_features, n_classes)\n",
    "        self.bias = None     # Shape: (n_classes,)\n",
    "\n",
    "    def _softmax(self, z):\n",
    "        \"\"\"\n",
    "        Compute softmax values for each set of scores in z.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        z : numpy.ndarray\n",
    "            Input array of shape (n_samples, n_classes).\n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray\n",
    "            Softmax probabilities of shape (n_samples, n_classes).\n",
    "        \"\"\"\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # For numerical stability\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def _one_hot(self, y, n_classes):\n",
    "        \"\"\"\n",
    "        Convert labels to one-hot encoding.\n",
    "        \"\"\"\n",
    "        one_hot = np.zeros((y.shape[0], n_classes))\n",
    "        one_hot[np.arange(y.shape[0]), y] = 1\n",
    "        return one_hot\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the softmax regression model using gradient descent.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray\n",
    "            Training data of shape (n_samples, n_features).\n",
    "        y : numpy.ndarray\n",
    "            Target values of shape (n_samples,), integer labels (0...n_classes-1).\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        n_classes = np.max(y) + 1\n",
    "        y_one_hot = self._one_hot(y, n_classes)\n",
    "\n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.zeros((n_features, n_classes))\n",
    "        self.bias = np.zeros(n_classes)\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            # Linear logits\n",
    "            logits = X @ self.weights + self.bias  # Shape: (n_samples, n_classes)\n",
    "            probs = self._softmax(logits)          # Shape: (n_samples, n_classes)\n",
    "\n",
    "            # Compute gradients\n",
    "            error = probs - y_one_hot              # Shape: (n_samples, n_classes)\n",
    "            dw = (X.T @ error) / n_samples         # Shape: (n_features, n_classes)\n",
    "            db = np.mean(error, axis=0)            # Shape: (n_classes,)\n",
    "\n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predict class probabilities for samples in X.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray\n",
    "            Input data of shape (n_samples, n_features).\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray\n",
    "            Predicted class probabilities of shape (n_samples, n_classes).\n",
    "        \"\"\"\n",
    "        logits = X @ self.weights + self.bias\n",
    "        return self._softmax(logits)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels for samples in X.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray\n",
    "            Input data of shape (n_samples, n_features).\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray\n",
    "            Predicted class labels (integers) of shape (n_samples,).\n",
    "        \"\"\"\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.argmax(proba, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d9777-7c48-4871-baeb-d651934b3be7",
   "metadata": {},
   "source": [
    "> ## Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa7d11f-015b-46b8-9cec-986947b46869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Regression accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Simple synthetic dataset (3 classes, 2 features)\n",
    "np.random.seed(42)\n",
    "n_samples = 120\n",
    "X_demo = np.vstack([\n",
    "        np.random.randn(n_samples//3, 2) + np.array([2, 2]),\n",
    "        np.random.randn(n_samples//3, 2) + np.array([-2, -2]),\n",
    "        np.random.randn(n_samples//3, 2) + np.array([2, -2])\n",
    "    ])\n",
    "y_demo = np.array([0] * (n_samples//3) + [1] * (n_samples//3) + [2] * (n_samples//3))\n",
    "\n",
    "# Train softmax regression\n",
    "model = SoftmaxRegressionScratch(learning_rate=0.1, iterations=1000)\n",
    "model.fit(X_demo, y_demo)\n",
    "\n",
    "preds = model.predict(X_demo)\n",
    "accuracy = np.mean(preds == y_demo)\n",
    "print(\"Softmax Regression accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
